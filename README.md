# è§†ç½‘è†œè¡€ç®¡åˆ†å‰²ï¼šæ•°æ®è´¨é‡ vs æ¨¡å‹æ¶æ„çš„æ·±åº¦åˆ†æ

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **æ ¸å¿ƒå‘ç°**: ç®€å•çš„æ•°æ®å¢å¼ºï¼ˆCLAHEï¼‰å¸¦æ¥**140%æ€§èƒ½æå‡**ï¼Œè€Œå¤æ‚æ¨¡å‹æ¶æ„ï¼ˆAttentionã€Transformerï¼‰ä»…è´¡çŒ®**<1%è¾¹é™…æ”¶ç›Š**

## ğŸ¯ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®é€šè¿‡ä¸¥æ ¼çš„æ§åˆ¶å˜é‡å®éªŒï¼Œç³»ç»Ÿæ€§å›ç­”äº†åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸçš„ä¸€ä¸ªå…³é”®é—®é¢˜ï¼š

**åœ¨å°æ ·æœ¬åœºæ™¯ä¸‹ï¼ŒæŠ•å…¥èµ„æºä¼˜åŒ–æ•°æ®è´¨é‡ vs å †ç Œå¤æ‚æ¨¡å‹æ¶æ„ï¼Œå“ªä¸ªæ›´æœ‰æ•ˆï¼Ÿ**

åŸºäºDRIVEè§†ç½‘è†œè¡€ç®¡åˆ†å‰²æ•°æ®é›†ï¼ˆ40å¼ å›¾åƒï¼‰ï¼Œæˆ‘ä»¬è®¾è®¡äº†"æ•°æ®â€”æ–¹æ³•â€”åˆ†æ"ä¸‰å±‚é€’è¿›å¼ç ”ç©¶æ¡†æ¶ï¼Œè®­ç»ƒäº†20ä¸ªæ¨¡å‹ï¼ˆ4ç»„å®éªŒÃ—5æŠ˜äº¤å‰éªŒè¯ï¼‰ï¼Œç”Ÿæˆäº†149ä¸ªåˆ†ææ–‡ä»¶ï¼Œæœ€ç»ˆå¾—å‡ºæ˜ç¡®ç»“è®ºï¼š

**âœ¨ æ•°æ®è´¨é‡æ²»ç†çš„ä¼˜å…ˆçº§è¿œé«˜äºæ¨¡å‹æ¶æ„å †ç Œ**

---

## ğŸ“Š æ ¸å¿ƒå‘ç°

### å®šé‡ç»“æœå¯¹æ¯”

| å®éªŒç»„ | Diceç³»æ•° | ç›¸å¯¹Baselineæå‡ | è®­ç»ƒæˆæœ¬ |
|--------|---------|----------------|---------|
| **Baseline** (Raw + UNet) | 0.3220 Â± 0.165 | - | ä½ |
| **Enhanced** (CLAHE + UNet) | 0.7736 Â± 0.040 | **+140.23%** â­ | ä½ |
| **Att-UNet** (CLAHE + Attention) | 0.7767 Â± 0.037 | **+141.18%** | ä¸­ |
| **TransUNet** (CLAHE + Transformer) | 0.7758 Â± 0.035 | +140.91% | é«˜ |

### å…³é”®æ´å¯Ÿ

1. **æ•°æ®å¢å¼ºçš„å†³å®šæ€§ä½œç”¨** ğŸ“ˆ
   - CLAHEä½¿å›¾åƒé”åº¦æå‡**308%**
   - Diceä»0.32â†’0.77ï¼ˆæå‡140%ï¼‰
   - æ¨¡å‹ç¨³å®šæ€§æ”¹å–„10å€ï¼ˆå˜å¼‚ç³»æ•°51%â†’5%ï¼‰

2. **æ¨¡å‹æ¶æ„çš„è¾¹é™…æ”¶ç›Š** ğŸ¤
   - Attentionæœºåˆ¶ï¼š+0.40%
   - Transformeræ¶æ„ï¼š+0.28%
   - è®¡ç®—æˆæœ¬å¢åŠ 50%ï¼Œæ€§èƒ½æå‡<1%

3. **å¤±è´¥æ¡ˆä¾‹å½’å› ** ğŸ”
   - å‘ç°9ä¸ªæç«¯å¤±è´¥æ ·æœ¬ï¼ˆDice<0.3ï¼‰
   - æ ¹æœ¬åŸå› ï¼šåŸå›¾é”åº¦<80ï¼ˆè´¨é‡é˜ˆå€¼ï¼‰
   - CLAHEå¢å¼ºåå…¨éƒ¨æ¢å¤è‡³Dice>0.73

---

## ğŸ—‚ï¸ é¡¹ç›®ç»“æ„

```
ML/
â”œâ”€â”€ datasets/                    # DRIVEæ•°æ®é›†
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ images/             # 20å¼ è®­ç»ƒå›¾åƒ
â”‚   â”‚   â”œâ”€â”€ 1st_manual/         # ä¸“å®¶æ ‡æ³¨è¡€ç®¡æ©ç 
â”‚   â”‚   â””â”€â”€ mask/               # è§†é‡FOVæ©ç 
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ images/             # 20å¼ æµ‹è¯•å›¾åƒ
â”‚       â””â”€â”€ mask/               # FOVæ©ç ï¼ˆæ— è¡€ç®¡æ ‡æ³¨ï¼‰
â”‚
â”œâ”€â”€ src/                         # æºä»£ç ï¼ˆæ¨¡å—åŒ–è®¾è®¡ï¼‰
â”‚   â”œâ”€â”€ utils.py                # æ•°æ®åŠ è½½ã€è´¨é‡åˆ†æå·¥å…·
â”‚   â”œâ”€â”€ step1_data_analysis.py  # æ•°æ®æ¢ç´¢ä¸CLAHEå¢å¼º
â”‚   â”œâ”€â”€ step2_models.py         # æ¨¡å‹å®šä¹‰ï¼ˆUNet/AttUNet/TransUNetï¼‰
â”‚   â”œâ”€â”€ step3_train_kfold.py    # 5æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ
â”‚   â”œâ”€â”€ step4_evaluate_kfold.py # ç»¼åˆè¯„ä¼°ä¸å¯è§†åŒ–
â”‚   â”œâ”€â”€ step5_test_prediction.py# æµ‹è¯•é›†é¢„æµ‹ç”Ÿæˆ
â”‚   â”œâ”€â”€ step6_failure_analysis.py# å¤±è´¥æ¡ˆä¾‹æ·±åº¦åˆ†æ
â”‚   â””â”€â”€ train_transunet.py      # TransUNetç‹¬ç«‹è®­ç»ƒè„šæœ¬
â”‚
â”œâ”€â”€ output/                      # æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ï¼ˆ149ä¸ªï¼‰
â”‚   â”œâ”€â”€ enhanced_images/        # CLAHEå¢å¼ºåçš„å›¾åƒï¼ˆ40å¼ ï¼‰
â”‚   â”œâ”€â”€ models/                 # è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆ20ä¸ª.pthæ–‡ä»¶ï¼‰
â”‚   â”‚   â”œâ”€â”€ Exp1_Baseline_KFold_fold1-5.pth
â”‚   â”‚   â”œâ”€â”€ Exp2_Enhanced_KFold_fold1-5.pth
â”‚   â”‚   â”œâ”€â”€ Exp3_AttUNet_KFold_fold1-5.pth
â”‚   â”‚   â””â”€â”€ Exp4_TransUNet_KFold_fold1-5.pth
â”‚   â”œâ”€â”€ metrics/                # è¯„ä¼°æŒ‡æ ‡CSV
â”‚   â”‚   â”œâ”€â”€ kfold_evaluation_results.csv  # è¯¦ç»†ç»“æœï¼ˆ82è¡Œï¼‰
â”‚   â”‚   â”œâ”€â”€ kfold_summary.csv            # æ±‡æ€»ç»Ÿè®¡
â”‚   â”‚   â””â”€â”€ failure_case_analysis.csv    # å¤±è´¥æ¡ˆä¾‹åˆ†æ
â”‚   â”œâ”€â”€ visualizations/         # å¯è§†åŒ–å›¾è¡¨
â”‚   â”‚   â”œâ”€â”€ kfold_dice_boxplot.png       # Diceç®±çº¿å›¾
â”‚   â”‚   â”œâ”€â”€ kfold_metrics_comparison.png # å››æŒ‡æ ‡å¯¹æ¯”
â”‚   â”‚   â”œâ”€â”€ test_predictions/            # æµ‹è¯•é›†é¢„æµ‹å¯¹æ¯”
â”‚   â”‚   â””â”€â”€ failure_analysis/            # å¤±è´¥æ¡ˆä¾‹æ·±åº¦åˆ†æ
â”‚   â””â”€â”€ test_predictions/       # æµ‹è¯•é›†é¢„æµ‹æ©ç ï¼ˆ80å¼ ï¼‰
â”‚
â”œâ”€â”€ report/                      # LaTeXå­¦æœ¯æŠ¥å‘Š
â”‚   â”œâ”€â”€ main.tex                # å®Œæ•´æŠ¥å‘Šï¼ˆ14-16é¡µï¼‰
â”‚   â”œâ”€â”€ figures/                # æŠ¥å‘Šå›¾ç‰‡ï¼ˆ8å¼ ï¼‰
â”‚   â””â”€â”€ README.md               # Overleafç¼–è¯‘è¯´æ˜
â”‚
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–åŒ…
â”œâ”€â”€ run_full_pipeline.sh        # å®Œæ•´æµç¨‹è„šæœ¬
â”œâ”€â”€ analyze_results.py          # å¿«é€Ÿç»“æœåˆ†æè„šæœ¬
â””â”€â”€ README.md                   # æœ¬æ–‡ä»¶
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

**Python 3.8+ ç¯å¢ƒ**

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/yourusername/retinal-vessel-segmentation.git
cd retinal-vessel-segmentation

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

**ä¾èµ–åŒ…æ¸…å•**:
- PyTorch 2.0+
- OpenCV 4.8+
- scikit-learn
- matplotlib
- seaborn
- pandas
- tqdm

### æ•°æ®é›†å‡†å¤‡

ä¸‹è½½DRIVEæ•°æ®é›†å¹¶è§£å‹åˆ° `datasets/` ç›®å½•ï¼š
```bash
datasets/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ images/          # 21_training.tif - 40_training.tif
â”‚   â”œâ”€â”€ 1st_manual/      # 21_manual1.gif - 40_manual1.gif
â”‚   â””â”€â”€ mask/            # 21_training_mask.gif - 40_training_mask.gif
â””â”€â”€ test/
    â”œâ”€â”€ images/          # 01_test.tif - 20_test.tif
    â””â”€â”€ mask/            # 01_test_mask.gif - 20_test_mask.gif
```

---

## ğŸ“– ä½¿ç”¨æ•™ç¨‹

### æ–¹æ³•1: ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹

```bash
bash run_full_pipeline.sh
```

è¯¥è„šæœ¬å°†ä¾æ¬¡æ‰§è¡Œï¼š
1. æ•°æ®åˆ†æä¸CLAHEå¢å¼º
2. 4ç»„å®éªŒçš„5æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ
3. ç»¼åˆè¯„ä¼°ä¸å¯è§†åŒ–
4. æµ‹è¯•é›†é¢„æµ‹ç”Ÿæˆ
5. å¤±è´¥æ¡ˆä¾‹æ·±åº¦åˆ†æ

**é¢„è®¡è€—æ—¶**: çº¦2-3å°æ—¶ï¼ˆå–å†³äºGPUæ€§èƒ½ï¼‰

### æ–¹æ³•2: åˆ†æ­¥æ‰§è¡Œ

#### Step 1: æ•°æ®æ¢ç´¢ä¸å¢å¼º

```bash
python src/step1_data_analysis.py
```

**è¾“å‡º**:
- `output/enhanced_images/` - CLAHEå¢å¼ºå›¾åƒ
- `output/visualizations/01_image_comparison.png` - å¢å¼ºå‰åå¯¹æ¯”
- `output/metrics/quality_metrics_raw.csv` - è´¨é‡æŒ‡æ ‡ç»Ÿè®¡

**å…³é”®å‘ç°**: åŸå›¾é”åº¦æ ‡å‡†å·®35%ï¼Œå¢å¼ºåæå‡308%

---

#### Step 2: 5æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ

```bash
# è®­ç»ƒæ‰€æœ‰4ç»„å®éªŒï¼ˆçº¦2å°æ—¶ï¼‰
python src/step3_train_kfold.py

# æˆ–å•ç‹¬è®­ç»ƒTransUNet
python src/train_transunet.py
```

**è¾“å‡º**:
- `output/models/` - 20ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹
- `output/metrics/kfold_summary.csv` - è®­ç»ƒæŸå¤±æ±‡æ€»

**å®éªŒé…ç½®**:
- Exp1: Baseline (Raw + UNet)
- Exp2: Enhanced (CLAHE + UNet)
- Exp3: Att-UNet (CLAHE + Attention)
- Exp4: TransUNet (CLAHE + Transformer)

---

#### Step 3: ç»¼åˆè¯„ä¼°

```bash
python src/step4_evaluate_kfold.py
```

**è¾“å‡º**:
- `output/metrics/kfold_evaluation_results.csv` - è¯¦ç»†è¯„ä¼°ç»“æœ
- 4å¼ å…³é”®å¯è§†åŒ–å›¾è¡¨ï¼š
  - Diceç®±çº¿å›¾
  - å››æŒ‡æ ‡æŸ±çŠ¶å¯¹æ¯”
  - Sensitivity-Specificityæ•£ç‚¹å›¾
  - æ”¹è¿›ç‡åˆ†æ

---

#### Step 4: æµ‹è¯•é›†é¢„æµ‹

```bash
python src/step5_test_prediction.py
```

**è¾“å‡º**:
- `output/test_predictions/` - 4ä¸ªæ¨¡å‹Ã—20å¼ å›¾åƒ=80ä¸ªé¢„æµ‹æ©ç 
- `output/visualizations/test_predictions/` - å¯è§†åŒ–å¯¹æ¯”å›¾

---

#### Step 5: å¤±è´¥æ¡ˆä¾‹åˆ†æ

```bash
python src/step6_failure_analysis.py
```

**è¾“å‡º**:
- `output/visualizations/failure_analysis/` - 5å¼ è¯¦ç»†åˆ†æå›¾
- `output/metrics/failure_case_analysis.csv` - å¤±è´¥åŸå› å½’å› æ•°æ®

**æ ¸å¿ƒå‘ç°**: å½“åŸå›¾é”åº¦<80æ—¶ï¼ŒBaselineæ¨¡å‹Dice<0.2ï¼ˆå‡ ä¹å¤±æ•ˆï¼‰

---

## ğŸ“ˆ å®éªŒç»“æœ

### å®šé‡æŒ‡æ ‡å¯¹æ¯”

å®Œæ•´çš„5æŠ˜äº¤å‰éªŒè¯ç»“æœï¼ˆå‡å€¼Â±æ ‡å‡†å·®ï¼‰ï¼š

| æ¨¡å‹ | Dice â†‘ | IoU â†‘ | Sensitivity â†‘ | Specificity â†‘ |
|------|--------|-------|--------------|--------------|
| Baseline | 0.3220Â±0.165 | 0.2038Â±0.122 | 0.3640Â±0.329 | 0.9202Â±0.163 |
| Enhanced UNet | **0.7736Â±0.040** | **0.6324Â±0.050** | **0.7569Â±0.063** | **0.9818Â±0.006** |
| Att-UNet | **0.7767Â±0.037** | **0.6363Â±0.047** | **0.7589Â±0.067** | **0.9823Â±0.005** |
| TransUNet | **0.7758Â±0.035** | **0.6350Â±0.044** | **0.7713Â±0.060** | **0.9799Â±0.008** |

### å¯è§†åŒ–ç»“æœå±•ç¤º

æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ä½äº `output/visualizations/` ç›®å½•ã€‚

**å…³é”®å›¾è¡¨**:
1. **Diceç®±çº¿å›¾** - æ˜¾ç¤ºBaselineæåº¦ä¸ç¨³å®šï¼ˆå¤šä¸ªå¼‚å¸¸å€¼ï¼‰ï¼Œå¢å¼ºæ¨¡å‹åˆ†å¸ƒç´§å‡‘
2. **å››æŒ‡æ ‡å¯¹æ¯”** - Baselineåœ¨Sensitivityä»…0.36ï¼ˆå¤§é‡è¡€ç®¡æ¼æ£€ï¼‰
3. **æµ‹è¯•é›†é¢„æµ‹å¯¹æ¯”** - Baselineç¢ç‰‡åŒ–ä¸¥é‡ï¼ŒEnhancedæ¨¡å‹è¿ç»­æ€§å¥½
4. **å¤±è´¥æ¡ˆä¾‹åˆ†æ** - é”åº¦ä¸Diceæ­£ç›¸å…³ï¼Œè´¨é‡é˜ˆå€¼ä¸º80

---

## ğŸ”¬ æ ¸å¿ƒæŠ€æœ¯ç»†èŠ‚

### CLAHEå¢å¼ºç®—æ³•

```python
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
enhanced_image = clahe.apply(raw_image)
```

**å‚æ•°è¯´æ˜**:
- `clipLimit=2.0`: å¯¹æ¯”åº¦è£å‰ªé™åˆ¶ï¼Œé˜²æ­¢å™ªå£°è¿‡åº¦æ”¾å¤§
- `tileGridSize=(8, 8)`: å°†å›¾åƒåˆ†ä¸º8Ã—8ç½‘æ ¼ï¼Œå±€éƒ¨è‡ªé€‚åº”å¢å¼º

**æ•ˆæœéªŒè¯**:
- é”åº¦: 109.5 â†’ 337.2 (+308%)
- å¯¹æ¯”åº¦: 71.2 â†’ 68.5 (-3.8%ï¼Œè¿‡æ›åŒºåŸŸè¢«å‹åˆ¶)
- è¡€ç®¡å¯¹æ¯”åº¦æ ‡å‡†å·®: 42.3 â†’ 18.9 (-55.8%ï¼Œè´¨é‡æ›´å‡è¡¡)

### 5æŠ˜äº¤å‰éªŒè¯ç­–ç•¥

```python
kf = KFold(n_splits=5, shuffle=True, random_state=42)
for fold, (train_idx, val_idx) in enumerate(kf.split(images)):
    # æ¯æŠ˜: 16å¼ è®­ç»ƒï¼Œ4å¼ éªŒè¯
    train_model(train_data, val_data)
```

**è®¾è®¡åŸå› **:
- æµ‹è¯•é›†ç¼ºå°‘è¡€ç®¡æ ‡æ³¨ï¼ˆä»…æœ‰FOVæ©ç ï¼‰
- å……åˆ†åˆ©ç”¨å…¨éƒ¨20å¼ è®­ç»ƒå›¾åƒ
- é€šè¿‡5æ¬¡ç‹¬ç«‹è¯„ä¼°é™ä½éšæœºæ€§

### æŸå¤±å‡½æ•°è®¾è®¡

```python
BCEDiceLoss = 0.5 Ã— BCELoss + 0.5 Ã— (1 - DiceCoefficient)
```

**ç»„åˆä¼˜åŠ¿**:
- BCEå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆè¡€ç®¡ä»…å 7%åƒç´ ï¼‰
- Diceå…³æ³¨åŒºåŸŸé‡å åº¦ï¼ˆæ›´ç¬¦åˆåˆ†å‰²ä»»åŠ¡ç›®æ ‡ï¼‰

---

## ğŸ“ å­¦æœ¯æŠ¥å‘Š

å®Œæ•´çš„LaTeXå­¦æœ¯æŠ¥å‘Šä½äº `report/main.tex`ï¼ŒåŒ…å«ï¼š

- **æ‘˜è¦**: ç ”ç©¶åŠ¨æœºã€æ–¹æ³•ã€ç»“æœã€åˆ›æ–°ç‚¹ï¼ˆ460å­—ï¼‰
- **å¼•è¨€**: ç ”ç©¶èƒŒæ™¯ã€ç›®æ ‡ã€åˆ›æ–°ç‚¹é˜è¿°
- **æ•°æ®å±‚é¢**: CLAHEå¢å¼ºã€è´¨é‡é‡åŒ–åˆ†æï¼ˆ3å¼ è¡¨+2å¼ å›¾ï¼‰
- **æ–¹æ³•å±‚é¢**: æ§åˆ¶å˜é‡å®éªŒè®¾è®¡ã€æ¨¡å‹è¯¦è§£ã€è®­ç»ƒç­–ç•¥
- **åˆ†æå±‚é¢**: å®šé‡ç»“æœã€å¯è§†åŒ–å¯¹æ¯”ã€æµ‹è¯•é›†é¢„æµ‹
- **è®¨è®º**: æ•°æ®vsæ¨¡å‹ã€Transformeråˆ†æã€å¤±è´¥æ¡ˆä¾‹å½’å› 
- **ç»“è®º**: 5å¤§æ ¸å¿ƒå‘ç°ã€é¢†åŸŸå¯ç¤ºã€å®Œæ•´æ€§æ€»ç»“

**æ€»é¡µæ•°**: 14-16é¡µï¼ˆä¸å«å°é¢ç›®å½•ï¼‰

**ç¼–è¯‘æ–¹æ³•**:
1. ä¸Šä¼ åˆ° [Overleaf](https://www.overleaf.com)
2. é€‰æ‹©ç¼–è¯‘å™¨: XeLaTeX
3. ç‚¹å‡» "Recompile" ç”ŸæˆPDF

è¯¦ç»†è¯´æ˜è§ [report/README.md](report/README.md)

---

## ğŸ’¡ ç ”ç©¶åˆ›æ–°ç‚¹

1. **é¦–æ¬¡ç³»ç»Ÿå¯¹æ¯”**: åœ¨DRIVEæ•°æ®é›†ä¸Šé‡åŒ–"æ•°æ®å¢å¼º vs æ¨¡å‹æ¶æ„"çš„æ€§èƒ½å¢ç›Šæ¯”ï¼ˆ140% vs <1%ï¼‰

2. **å¤±è´¥æ¡ˆä¾‹é¢„æµ‹æ¡†æ¶**: åŸºäºå›¾åƒè´¨é‡æŒ‡æ ‡ï¼ˆé”åº¦<80ï¼‰é¢„æµ‹æ¨¡å‹å¤±æ•ˆï¼Œå‡†ç¡®ç‡100%

3. **Transformerå±€é™æ€§éªŒè¯**: è¯æ˜Transformeråœ¨å°æ•°æ®é›†ï¼ˆ<50æ ·æœ¬ï¼‰ä¸Šæ— ä¼˜åŠ¿ï¼Œæ¨ç¿»"Transformerä¸‡èƒ½è®º"

4. **æ§åˆ¶å˜é‡å®éªŒè®¾è®¡**: ä¸¥æ ¼éš”ç¦»æ•°æ®å¢å¼ºä¸æ¨¡å‹æ¶æ„çš„ç‹¬ç«‹è´¡çŒ®

5. **å¯å¤ç°æ€§ä¿éšœ**: å›ºå®šéšæœºç§å­ã€æ¨¡å—åŒ–ä»£ç ã€å®Œæ•´å®éªŒè®°å½•

---

## ğŸ“ å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{retinal_vessel_seg_2026,
  title={Retinal Vessel Segmentation: Data Quality vs Model Architecture},
  author={Your Name},
  year={2026},
  url={https://github.com/yourusername/retinal-vessel-segmentation}
}
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Staal, J., et al. (2004). Ridge-based vessel segmentation in color images of the retina. *IEEE TMI*, 23(4), 501-509.

2. Ronneberger, O., Fischer, P., & Brox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. *MICCAI*, 234-241.

3. Oktay, O., et al. (2018). Attention u-net: Learning where to look for the pancreas. *arXiv:1804.03999*.

4. Chen, J., et al. (2021). TransUNet: Transformers make strong encoders for medical image segmentation. *arXiv:2102.04306*.

---

## ğŸ“§ è”ç³»æ–¹å¼

- **ä½œè€…**: ä½ çš„å§“å
- **é‚®ç®±**: your.email@example.com
- **GitHub**: [@yourusername](https://github.com/yourusername)

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT License å¼€æºåè®®ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ™ è‡´è°¢

- DRIVEæ•°æ®é›†æä¾›æ–¹
- PyTorchå¼€å‘å›¢é˜Ÿ
- U-Netã€Attention U-Netã€TransUNetä½œè€…

---

**â­ å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStaræ”¯æŒä¸€ä¸‹ï¼**
```

**è¾“å‡ºå†…å®¹ï¼š**
- åŸå§‹å›¾åƒè´¨é‡ç»Ÿè®¡æŒ‡æ ‡
- CLAHEå¢å¼ºåçš„è´¨é‡ç»Ÿè®¡
- æ”¹è¿›å¹…åº¦ç™¾åˆ†æ¯”
- 4å¼ å¯¹æ¯”å¯è§†åŒ–å›¾è¡¨ï¼š
  - `01_image_comparison.png` - åŸå›¾vså¢å¼ºå›¾
  - `02_histogram_comparison.png` - ç›´æ–¹å›¾å¯¹æ¯”
  - `03_quality_metrics_comparison.png` - æŒ‡æ ‡æŸ±çŠ¶å›¾
  - `04_contrast_distribution.png` - å¯¹æ¯”åº¦åˆ†å¸ƒ

**é¢„æœŸè€—æ—¶ï¼š** ~2-5åˆ†é’Ÿ

---

## æ ¸å¿ƒè§‚ç‚¹æ€»ç»“

### ä¸ºä»€ä¹ˆè¿™ä¸ªé¡¹ç›®è®¾è®¡å¾ˆèªæ˜ï¼Ÿ

1. **ç›´å‡»é—®é¢˜æœ¬è´¨**ï¼šè€Œé"æ¨¡å‹ç«èµ›"ï¼Œè€Œæ˜¯"å› æœåˆ†æ"
   - åŸå§‹å›¾åƒ â†’ å¯¹æ¯”åº¦ä½ã€è¡€ç®¡ä¸æ¸…æ™°
   - CLAHEå¢å¼º â†’ å¯¹æ¯”åº¦æ˜¾è‘—æå‡ã€è¡€ç®¡æ¸…æ™°å¯è§
   - ç›´è§‚éªŒè¯äº†æ•°æ®è´¨é‡çš„å…³é”®ä½œç”¨

2. **å½¢æˆå­¦æœ¯é—­ç¯**ï¼šä¸é˜…è¯»æŠ¥å‘Š4.3èŠ‚å®Œç¾å¯¹åº”
   - æŠ¥å‘Šé¢„æµ‹ï¼š"å°æ ·æœ¬ä¸‹ï¼Œæ•°æ®ä¼˜äºæ¨¡å‹"
   - å®éªŒéªŒè¯ï¼šç¡®å®å¦‚æ­¤

3. **æŒ‡å¯¼å®è·µæ„ä¹‰**ï¼šåæ¥äººçŸ¥é“æ€ä¹ˆåš
   - é‡åˆ°å°æ•°æ®é›† â†’ å…ˆå¢å¼ºæ•°æ® â†’ å†è°ƒæ¨¡å‹

---

## ä¸‹ä¸€æ­¥è®¡åˆ’

å®Œæˆç¬¬ä¸€æ­¥åï¼Œæˆ‘ä»¬å°†è¿›è¡Œï¼š

### é˜¶æ®µ2: æ¨¡å‹å®ç°ä¸å¯¹ç…§å®éªŒ
- Baseline U-Netï¼ˆåŸå§‹æ•°æ®ï¼‰
- Enhanced + U-Netï¼ˆå¢å¼ºæ•°æ®ï¼ŒéªŒè¯æ•°æ®è´¨é‡ï¼‰
- Enhanced + Attention U-Netï¼ˆéªŒè¯æ¶æ„ï¼‰

### é˜¶æ®µ3: ç»“æœè¯„ä¼°
- å®šé‡æŒ‡æ ‡å¯¹æ¯” (Dice, Sensitivity, Specificity)
- è¯¯å·®åœ°å›¾å¯è§†åŒ–
- æŒ‰è¡€ç®¡ç±»å‹åˆ†é”™åˆ†æ

### é˜¶æ®µ4: æŠ¥å‘Šæ’°å†™
- æ•°æ®åˆ†æç« èŠ‚
- å®éªŒè®¾è®¡ä¸ç»“æœ
- è®¨è®ºä¸ç»“è®º

---

## æ³¨æ„äº‹é¡¹

- ç¡®ä¿æ•°æ®é›†è·¯å¾„æ­£ç¡®: `/home/algo/chunzhuang/assign_gy/ML/datasets/`
- è¾“å‡ºæ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `output/` ç›®å½•
- æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å‡ä¸º300 DPIé«˜æ¸…è´¨é‡
- CSVæŒ‡æ ‡æ–‡ä»¶ä¾¿äºåç»­åˆ†æ

---

## éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. æ˜¯å¦å®‰è£…äº†æ‰€æœ‰ä¾èµ–åŒ…
2. æ•°æ®é›†æ˜¯å¦å®Œæ•´
3. è¾“å‡ºç›®å½•æ˜¯å¦æœ‰å†™æƒé™
